{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d01055-6760-47a2-a8d3-a1a0b89d6626",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e7f5eb-cc82-4593-b008-70e85abb5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aocd import get_data\n",
    "from aocd import submit\n",
    "import unittest\n",
    "\n",
    "day = 13\n",
    "year = 2023\n",
    "\n",
    "def submit_part_a(answer):\n",
    "    submit(answer, part=\"a\", day=day, year=year)\n",
    "\n",
    "def submit_part_b(answer):\n",
    "    submit(answer, part=\"b\", day=day, year=year)\n",
    "\n",
    "input = get_data(day=day, year=year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68392b4d-521f-4128-8c4b-b1fb158d496b",
   "metadata": {},
   "source": [
    "## Parsing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa73f82e-2fc4-49e4-9def-a521c4c2dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(input):\n",
    "    return [[list(line) for line in pattern.split(\"\\n\")] for pattern in input.split(\"\\n\\n\")]\n",
    "\n",
    "patterns = parse(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821cc6c-8768-4db1-93dc-dfb00e9af254",
   "metadata": {},
   "source": [
    "## Example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87120b03-12a1-4cf6-b512-2b43b6de4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_example_pattern = [\n",
    "    ['#', '.', '#', '#', '.', '.', '#', '#', '.'],\n",
    "    ['.', '.', '#', '.', '#', '#', '.', '#', '.'],\n",
    "    ['#', '#', '.', '.', '.', '.', '.', '.', '#'],\n",
    "    ['#', '#', '.', '.', '.', '.', '.', '.', '#'],\n",
    "    ['.', '.', '#', '.', '#', '#', '.', '#', '.'],\n",
    "    ['.', '.', '#', '#', '.', '.', '#', '#', '.'],\n",
    "    ['#', '.', '#', '.', '#', '#', '.', '#', '.']\n",
    "]\n",
    "\n",
    "second_example_pattern = [\n",
    "    ['#', '.', '.', '.', '#', '#', '.', '.', '#'],\n",
    "    ['#', '.', '.', '.', '.', '#', '.', '.', '#'],\n",
    "    ['.', '.', '#', '#', '.', '.', '#', '#', '#'],\n",
    "    ['#', '#', '#', '#', '#', '.', '#', '#', '.'],\n",
    "    ['#', '#', '#', '#', '#', '.', '#', '#', '.'],\n",
    "    ['.', '.', '#', '#', '.', '.', '#', '#', '#'],\n",
    "    ['#', '.', '.', '.', '.', '#', '.', '.', '#']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a670e-8a30-4deb-9733-f4b1a56ed6ce",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a81f02-32b5-42e1-95ad-ac54fa112de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_horizontal_mirror_line(pattern: [[str]], mirror_line: (int, int), nb_smudges_accepted: int = 0):\n",
    "    first_row, second_row = mirror_line\n",
    "    if first_row <0 or second_row >= len(pattern):\n",
    "        return False\n",
    "    remaining_smudges_accepted = nb_smudges_accepted\n",
    "    while first_row >=0 and second_row < len(pattern):\n",
    "        nb_smudges = sum(a != b for a,b in zip(pattern[first_row], pattern[second_row]))\n",
    "        if nb_smudges > remaining_smudges_accepted:\n",
    "            return False\n",
    "        remaining_smudges_accepted -= nb_smudges\n",
    "        first_row -= 1\n",
    "        second_row += 1\n",
    "    # as we must have exactly \"nb_smudges_accepted\" smudges,\n",
    "    # if we succeded to find a reflection with less smudges, it's not good\n",
    "    return remaining_smudges_accepted == 0\n",
    "\n",
    "\n",
    "def find_horizontal_mirror(pattern: [[str]], nb_smudges_accepted: int = 0) -> (int, int):\n",
    "    middle_row = int(len(pattern)/2)\n",
    "    first_row, second_row = middle_row, middle_row\n",
    "\n",
    "    for i in range(middle_row+1):\n",
    "        if is_a_horizontal_mirror_line(pattern, (first_row-1, first_row), nb_smudges_accepted):\n",
    "            return (first_row-1, first_row)\n",
    "        if is_a_horizontal_mirror_line(pattern, (second_row, second_row+1), nb_smudges_accepted):\n",
    "            return (second_row, second_row+1)\n",
    "        first_row -= 1\n",
    "        second_row += 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_vertical_mirror(pattern: [[str]], nb_smudges_accepted: int = 0) -> (int, int):\n",
    "    # transpose the pattern rows become cols and cols become rows\n",
    "    transposed_pattern = list(zip(*pattern))\n",
    "    return find_horizontal_mirror(transposed_pattern, nb_smudges_accepted)\n",
    "\n",
    "\n",
    "def find_mirror(pattern: [[str]], nb_smudges_accepted: int = 0) -> (int, int, int):\n",
    "    mult = 100\n",
    "    mirror = find_horizontal_mirror(pattern, nb_smudges_accepted)\n",
    "    if mirror is None:\n",
    "        mult = 1\n",
    "        mirror = find_vertical_mirror(pattern, nb_smudges_accepted)\n",
    "    return (mirror[0], mirror[1], mult)\n",
    "\n",
    "\n",
    "assert find_vertical_mirror(second_example_pattern) == None\n",
    "assert find_vertical_mirror(first_example_pattern) == (4, 5)\n",
    "\n",
    "assert find_horizontal_mirror(second_example_pattern) == (3, 4)\n",
    "assert find_horizontal_mirror(first_example_pattern) == None\n",
    "\n",
    "assert find_mirror(first_example_pattern) == (4, 5, 1)\n",
    "assert find_mirror(second_example_pattern) == (3, 4, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a619c7bc-0690-4992-95e6-6c43186edde5",
   "metadata": {},
   "source": [
    "## Resoling the first part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ceba2-3882-4a64-ac91-599d9cb64459",
   "metadata": {},
   "source": [
    "### The example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e9dbdb-ef78-4561-b1ff-f2c6aef93189",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_patterns = [first_example_pattern, second_example_pattern]\n",
    "example_mirrors = [find_mirror(pattern) for pattern in example_patterns]\n",
    "example_answer = sum((mirror[0]+1) * mirror[2] for mirror in example_mirrors)\n",
    "assert example_answer == 405"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5e725-7db0-466e-b5f0-a98dd86e3f3a",
   "metadata": {},
   "source": [
    "### The real input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0b11fe-779c-4060-9fa7-8bef1a06ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33735\n",
      "CPU times: user 6.59 ms, sys: 1.1 ms, total: 7.7 ms\n",
      "Wall time: 7.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mirrors = [find_mirror(pattern) for pattern in patterns]\n",
    "first_answer = sum((mirror[0]+1) * mirror[2] for mirror in mirrors)\n",
    "print(first_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6afcb0-34fb-402e-b8c0-f01b0db6fda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aocd will not submit that answer again. At 2023-12-13 15:07:12.923141-05:00 you've previously submitted 33735 and the server responded with:\n",
      "\u001b[32mThat's the right answer!  You are one gold star closer to restoring snow operations. [Continue to Part Two]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "submit_part_a(first_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c281022-f4fd-4177-beb1-581ad7b58112",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f743e-82e7-459c-a132-fdb97ad26106",
   "metadata": {},
   "source": [
    "### Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf77623-60bf-43df-ae61-83404df2df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert find_vertical_mirror(second_example_pattern, 1) == None\n",
    "assert find_vertical_mirror(first_example_pattern, 1) == None\n",
    "\n",
    "assert find_horizontal_mirror(second_example_pattern, 1) == (0, 1)\n",
    "assert find_horizontal_mirror(first_example_pattern, 1) == (2, 3)\n",
    "\n",
    "assert find_mirror(first_example_pattern, 1) == (2, 3, 100)\n",
    "assert find_mirror(second_example_pattern, 1) == (0, 1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca75118-55c2-4472-8b90-0b7e224deaab",
   "metadata": {},
   "source": [
    "### The example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554bcd29-635b-4bec-b1b4-02075201f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_patterns = [first_example_pattern, second_example_pattern]\n",
    "example_mirrors = [find_mirror(pattern, 1) for pattern in example_patterns]\n",
    "example_answer = sum((mirror[0]+1) * mirror[2] for mirror in example_mirrors)\n",
    "assert example_answer == 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb31f170-b554-4a5c-9ea8-0af3f3a29af4",
   "metadata": {},
   "source": [
    "### The real input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e707eba-b473-43c0-8de9-981551d339b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38063\n",
      "CPU times: user 6.94 ms, sys: 1.8 ms, total: 8.75 ms\n",
      "Wall time: 8.74 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mirrors = [find_mirror(pattern, nb_smudges_accepted=1) for pattern in patterns]\n",
    "second_answer = sum((mirror[0]+1) * mirror[2] for mirror in mirrors)\n",
    "print(second_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdf2a23c-3a54-40f0-8851-027f53f9bce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aocd will not submit that answer again. At 2023-12-13 15:48:16.449033-05:00 you've previously submitted 38063 and the server responded with:\n",
      "\u001b[32mThat's the right answer!  You are one gold star closer to restoring snow operations.You have completed Day 13! You can [Shareon\n",
      "  Twitter\n",
      "Mastodon] this victory or [Return to Your Advent Calendar].\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "submit_part_b(second_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
